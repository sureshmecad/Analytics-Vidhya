{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\"> 1. Import necessary Libraries </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "submission = pd.read_csv(\"sample_submission_UVKGLZE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1        Reconstructing Subject-Specific Effect Maps   \n",
       "1   2                 Rotation Invariance Neural Network   \n",
       "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3   4  A finite element approximation for the stochas...   \n",
       "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
       "\n",
       "                                            ABSTRACT  Computer Science  \\\n",
       "0    Predictive models allow subject-specific inf...                 1   \n",
       "1    Rotation invariance and translation invarian...                 1   \n",
       "2    We introduce and develop the notion of spher...                 0   \n",
       "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "\n",
       "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0        0            0           0                     0   \n",
       "1        0            0           0                     0   \n",
       "2        0            1           0                     0   \n",
       "3        0            1           0                     0   \n",
       "4        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20973</td>\n",
       "      <td>Closed-form Marginal Likelihood in Gamma-Poiss...</td>\n",
       "      <td>We present novel understandings of the Gamma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20974</td>\n",
       "      <td>Laboratory mid-IR spectra of equilibrated and ...</td>\n",
       "      <td>Meteorites contain minerals from Solar Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20975</td>\n",
       "      <td>Case For Static AMSDU Aggregation in WLANs</td>\n",
       "      <td>Frame aggregation is a mechanism by which mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20976</td>\n",
       "      <td>The $Gaia$-ESO Survey: the inner disk intermed...</td>\n",
       "      <td>Milky Way open clusters are very diverse in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20977</td>\n",
       "      <td>Witness-Functions versus Interpretation-Functi...</td>\n",
       "      <td>Proving that a cryptographic protocol is cor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              TITLE  \\\n",
       "0  20973  Closed-form Marginal Likelihood in Gamma-Poiss...   \n",
       "1  20974  Laboratory mid-IR spectra of equilibrated and ...   \n",
       "2  20975         Case For Static AMSDU Aggregation in WLANs   \n",
       "3  20976  The $Gaia$-ESO Survey: the inner disk intermed...   \n",
       "4  20977  Witness-Functions versus Interpretation-Functi...   \n",
       "\n",
       "                                            ABSTRACT  \n",
       "0    We present novel understandings of the Gamma...  \n",
       "1    Meteorites contain minerals from Solar Syste...  \n",
       "2    Frame aggregation is a mechanism by which mu...  \n",
       "3    Milky Way open clusters are very diverse in ...  \n",
       "4    Proving that a cryptographic protocol is cor...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Computer Science  Physics  Mathematics  Statistics  \\\n",
       "0  20973                 0        0            0           0   \n",
       "1  20974                 0        0            0           0   \n",
       "2  20975                 0        0            0           0   \n",
       "3  20976                 0        0            0           0   \n",
       "4  20977                 0        0            0           0   \n",
       "\n",
       "   Quantitative Biology  Quantitative Finance  \n",
       "0                     0                     0  \n",
       "1                     0                     0  \n",
       "2                     0                     0  \n",
       "3                     0                     0  \n",
       "4                     0                     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head())\n",
    "display(test.head())\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20972, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8989, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8989, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.shape)\n",
    "display(test.shape)\n",
    "display(submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Spinor analysis                                                                                                        1\n",
       "Transient flows in active porous media                                                                                 1\n",
       "A promise checked is a promise kept: Inspection Testing                                                                1\n",
       "Observation of surface plasmon polaritons in 2D electron gas of surface electron accumulation in InN nanostructures    1\n",
       "Logo Synthesis and Manipulation with Clustered Generative Adversarial Networks                                         1\n",
       "                                                                                                                      ..\n",
       "K-theory of line bundles and smooth varieties                                                                          1\n",
       "Variational Probability Flow for Biologically Plausible Training of Deep Neural Networks                               1\n",
       "Kinetics of Protein-DNA Interactions: First-Passage Analysis                                                           1\n",
       "Photospheric Emission of Gamma-Ray Bursts                                                                              1\n",
       "A Generalized Accelerated Composite Gradient Method: Uniting Nesterov's Fast Gradient Method and FISTA                 1\n",
       "Name: TITLE, Length: 20972, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transfer Learning and Organic Computing for Autonomous Vehicles                                 1\n",
       "Ultra-diffuse and Ultra-compact Galaxies in the Frontier Fields Cluster Abell 2744              1\n",
       "Inspiring Computer Vision System Solutions                                                      1\n",
       "A rank inequality for the annular Khovanov homology of 2-periodic links                         1\n",
       "A General Approximation Method for Bicriteria Minimization Problems                             1\n",
       "                                                                                               ..\n",
       "Cointegrated Density-Valued Linear Processes                                                    1\n",
       "Performance Analysis of Low Latency Multiple Full-Duplex Selective Decode and Forward Relays    1\n",
       "Wireless Full-duplex Medium Access Control for Enhancing Energy Efficiency                      1\n",
       "Newtonian Limits of Isolated Cosmological Systems on Long Time Scales                           1\n",
       "Categorizing Variants of Goodhart's Law                                                         1\n",
       "Name: TITLE, Length: 8989, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.TITLE.value_counts())\n",
    "print(\"_\"*120)\n",
    "display(test.TITLE.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20972"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8989"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.TITLE.nunique())\n",
    "print(\"_\"*120)\n",
    "display(test.TITLE.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABSTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  The use of drug combinations, termed polypharmacy, is common to treat\\npatients with complex diseases and co-existing conditions. However, a major\\nconsequence of polypharmacy is a much higher risk of adverse side effects for\\nthe patient. Polypharmacy side effects emerge because of drug-drug\\ninteractions, in which activity of one drug may change if taken with another\\ndrug. The knowledge of drug interactions is limited because these complex\\nrelationships are rare, and are usually not observed in relatively small\\nclinical testing. Discovering polypharmacy side effects thus remains an\\nimportant challenge with significant implications for patient mortality. Here,\\nwe present Decagon, an approach for modeling polypharmacy side effects. The\\napproach constructs a multimodal graph of protein-protein interactions,\\ndrug-protein target interactions, and the polypharmacy side effects, which are\\nrepresented as drug-drug interactions, where each side effect is an edge of a\\ndifferent type. Decagon is developed specifically to handle such multimodal\\ngraphs with a large number of edge types. Our approach develops a new graph\\nconvolutional neural network for multirelational link prediction in multimodal\\nnetworks. Decagon predicts the exact side effect, if any, through which a given\\ndrug combination manifests clinically. Decagon accurately predicts polypharmacy\\nside effects, outperforming baselines by up to 69%. We find that it\\nautomatically learns representations of side effects indicative of\\nco-occurrence of polypharmacy in patients. Furthermore, Decagon models\\nparticularly well side effects with a strong molecular basis, while on\\npredominantly non-molecular side effects, it achieves good performance because\\nof effective sharing of model parameters across edge types. Decagon creates\\nopportunities to use large pharmacogenomic and patient data to flag and\\nprioritize side effects for follow-up analysis.\\n    1\n",
       "  The basic reproduction number ($R_0$) is a threshold parameter for disease\\nextinction or survival in isolated populations. However no human population is\\nfully isolated from other human or animal populations. We use compartmental\\nmodels to derive simple rules for the basic reproduction number for populations\\nwith local person-to-person transmission and exposure from some other source:\\neither a reservoir exposure or imported cases. We introduce the idea of a\\nreservoir-driven or importation-driven disease: diseases that would become\\nextinct in the population of interest without reservoir exposure or imported\\ncases (since $R_0<1$), but nevertheless may be sufficiently transmissible that\\nmany or most infections are acquired from humans in that population. We show\\nthat in the simplest case, $R_0<1$ if and only if the proportion of infections\\nacquired from the external source exceeds the disease prevalence and explore\\nhow population heterogeneity and the interactions of multiple strains affect\\nthis rule. We apply these rules in two cases studies of Clostridium difficile\\ninfection and colonisation: C. difficile in the hospital setting accounting for\\nimported cases, and C. difficile in the general human population accounting for\\nexposure to animal reservoirs. We demonstrate that even the hospital-adapted,\\nhighly-transmissible NAP1/RT027 strain of C. difficile had a reproduction\\nnumber <1 in a landmark study of hospitalised patients and therefore was\\nsustained by colonised and infected admissions to the study hospital. We argue\\nthat C. difficile should be considered reservoir-driven if as little as 13.0%\\nof transmission can be attributed to animal reservoirs.\\n                                                                                                                                                                                                                                                   1\n",
       "  In the last decade, deep learning has contributed to advances in a wide range\\ncomputer vision tasks including texture analysis. This paper explores a new\\napproach for texture segmentation using deep convolutional neural networks,\\nsharing important ideas with classic filter bank based texture segmentation\\nmethods. Several methods are developed to train Fully Convolutional Networks to\\nsegment textures in various applications. We show in particular that these\\nnetworks can learn to recognize and segment a type of texture, e.g. wood and\\ngrass from texture recognition datasets (no training segmentation). We\\ndemonstrate that Fully Convolutional Networks can learn from repetitive\\npatterns to segment a particular texture from a single image or even a part of\\nan image. We take advantage of these findings to develop a method that is\\nevaluated on a series of supervised and unsupervised experiments and improve\\nthe state of the art on the Prague texture segmentation datasets.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
       "  The iterative ensemble Kalman filter (IEnKF) in a deterministic framework was\\nintroduced in Sakov et al. (2012) to extend the ensemble Kalman filter (EnKF)\\nand improve its performance in mildly up to strongly nonlinear cases.\\nHowever, the IEnKF assumes that the model is perfect. This assumption\\nsimplified the update of the system at a time different from the observation\\ntime, which made it natural to apply the IEnKF for smoothing. In this study, we\\ngeneralise the IEnKF to the case of imperfect model with additive model error.\\nThe new method called IEnKF-Q conducts a Gauss-Newton minimisation in\\nensemble space. It combines the propagated analysed ensemble anomalies from the\\nprevious cycle and model noise ensemble anomalies into a single ensemble of\\nanomalies, and by doing so takes an algebraic form similar to that of the\\nIEnKF. The performance of the IEnKF-Q is tested in a number of experiments with\\nthe Lorenz-96 model, which show that the method consistently outperforms both\\nthe EnKF and the IEnKF naively modified to accommodate additive model noise.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               1\n",
       "  Plasma turbulence at scales of the order of the ion inertial length is\\nmediated by several mechanisms, including linear wave damping, magnetic\\nreconnection, formation and dissipation of thin current sheets, stochastic\\nheating. It is now understood that the presence of localized coherent\\nstructures enhances the dissipation channels and the kinetic features of the\\nplasma. However, no formal way of quantifying the relationship between\\nscale-to-scale energy transfer and the presence of spatial structures has so\\nfar been presented. In this letter we quantify such relationship analyzing the\\nresults of a two-dimensional high-resolution Hall-MHD simulation. In\\nparticular, we employ the technique of space-filtering to derive a spectral\\nenergy flux term which defines, in any point of the computational domain, the\\nsigned flux of spectral energy across a given wavenumber. The characterization\\nof coherent structures is performed by means of a traditional two-dimensional\\nwavelet transformation. By studying the correlation between the spectral energy\\nflux and the wavelet amplitude, we demonstrate the strong relationship between\\nscale-to-scale transfer and coherent structures. Furthermore, by conditioning\\none quantity with respect to the other, we are able for the first time to\\nquantify the inhomogeneity of the turbulence cascade induced by topological\\nstructures in the magnetic field. Taking into account the low filling-factor of\\ncoherent structures (i.e. they cover a small portion of space), it emerges that\\n80% of the spectral energy transfer (both in the direct and inverse cascade\\ndirections) is localized in about 50% of space, and 50% of the energy transfer\\nis localized in only 25% of space.\\n                                                                                                                                                                                                                    1\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ..\n",
       "  A* is a best-first search algorithm for finding optimal-cost paths in graphs.\\nA* benefits significantly from parallelism because in many applications, A* is\\nlimited by memory usage, so distributed memory implementations of A* that use\\nall of the aggregate memory on the cluster enable problems that can not be\\nsolved by serial, single-machine implementations to be solved. We survey\\napproaches to parallel A*, focusing on decentralized approaches to A* which\\npartition the state space among processors. We also survey approaches to\\nparallel, limited-memory variants of A* such as parallel IDA*.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1\n",
       "  Modern deep neural networks (DNNs) spend a large amount of their execution\\ntime computing convolutions. Winograd's minimal algorithm for small\\nconvolutions can greatly reduce the number of arithmetic operations. However, a\\nlarge reduction in floating point (FP) operations in these algorithms can\\nresult in poor numeric accuracy. In this paper we analyse the FP error and\\nprove boundaries on the error. We show that the \"modified\" algorithm gives a\\nsignificantly better accuracy of the result. We propose several methods for\\nreducing FP error of these algorithms. Minimal convolution algorithms depend on\\nthe selection of several numeric \\textit{points} that have a large impact on\\nthe accuracy of the result. We propose a canonical evaluation ordering that\\nboth reduces FP error and the size of the search space based on Huffman coding.\\nWe study point selection experimentally, and find empirically good points. We\\nalso identify the main factors that associated with sets of points that result\\nin a low error. In addition, we explore other methods to reduce FP error,\\nincluding mixed-precision convolution, and pairwise addition across DNN\\nchannels. Using our methods we can significantly reduce FP error for a given\\nblock size, which allows larger block sizes and reduced computation.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
       "  Interpretability has become an important issue in the machine learning field,\\nalong with the success of layered neural networks in various practical tasks.\\nSince a trained layered neural network consists of a complex nonlinear\\nrelationship between large number of parameters, we failed to understand how\\nthey could achieve input-output mappings with a given data set. In this paper,\\nwe propose the non-negative task decomposition method, which applies\\nnon-negative matrix factorization to a trained layered neural network. This\\nenables us to decompose the inference mechanism of a trained layered neural\\nnetwork into multiple principal tasks of input-output mapping, and reveal the\\nroles of hidden units in terms of their contribution to each principal task.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1\n",
       "  This paper investigates estimation of the mean vector under invariant\\nquadratic loss for a spherically symmetric location family with a residual\\nvector with density of the form $\\nf(x,u)=\\eta^{(p+n)/2}f(\\eta\\{\\|x-\\theta\\|^2+\\|u\\|^2\\}) $, where $\\eta$ is\\nunknown. We show that the natural estimator $x$ is admissible for $p=1,2$.\\nAlso, for $p\\geq 3$, we find classes of generalized Bayes estimators that are\\nadmissible within the class of equivariant estimators of the form\\n$\\{1-\\xi(x/\\|u\\|)\\}x$. In the Gaussian case, a variant of the James--Stein\\nestimator, $[1-\\{(p-2)/(n+2)\\}/\\{\\|x\\|^2/\\|u\\|^2+(p-2)/(n+2)+1\\}]x$, which\\ndominates the natural estimator $x$, is also admissible within this class. We\\nalso study the related regression model.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1\n",
       "  Mobile edge caching enables content delivery directly within the radio access\\nnetwork, which effectively alleviates the backhaul burden and reduces\\nround-trip latency. To fully exploit the edge resources, the most popular\\ncontents should be identified and cached. Observing that content popularity\\nvaries greatly at different locations, to maximize local hit rate, this paper\\nproposes an online learning algorithm that dynamically predicts content hit\\nrate, and makes location-differentiated caching decisions. Specifically, a\\nlinear model is used to estimate the future hit rate. Considering the\\nvariations in user demand, a perturbation is added to the estimation to account\\nfor uncertainty. The proposed learning algorithm requires no training phase,\\nand hence is adaptive to the time-varying content popularity profile.\\nTheoretical analysis indicates that the proposed algorithm asymptotically\\napproaches the optimal policy in the long term. Extensive simulations based on\\nreal world traces show that, the proposed algorithm achieves higher hit rate\\nand better adaptiveness to content popularity fluctuation, compared with other\\nschemes.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1\n",
       "Name: ABSTRACT, Length: 20972, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  Here, we develop numerical methods for finite-state mean-field games (MFGs)\\nthat satisfy a monotonicity condition. MFGs are determined by a system of\\ndifferential equations with initial and terminal boundary conditions. These\\nnon-standard conditions are the main difficulty in the numerical approximation\\nof solutions. Using the monotonicity condition, we build a flow that is a\\ncontraction and whose fixed points solve the MFG, both for stationary and\\ntime-dependent problems. We illustrate our methods in a MFG modeling the\\nparadigm-shift problem.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1\n",
       "  We study the problem of domain adaptation for neural abstractive\\nsummarization. We make initial efforts in investigating what information can be\\ntransferred to a new domain. Experimental results on news stories and opinion\\narticles indicate that neural summarization model benefits from pre-training\\nbased on extractive summaries. We also find that the combination of in-domain\\nand out-of-domain setup yields better summaries when in-domain data is\\ninsufficient. Further analysis shows that, the model is capable to select\\nsalient content even trained on out-of-domain data, but requires in-domain data\\nto capture the style for a target domain.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1\n",
       "  A C*-algebra $A$ is said to be stable if it is isomorphic to $A \\otimes\\nK(\\ell_2)$. Hjelmborg and R\\o rdam have shown that countable inductive limits\\nof separable stable C*-algebras are stable. We show that this is no longer true\\nin the nonseparable context even for the most natural case of an uncountable\\ninductive limit of an increasing chain of separable stable and AF ideals: we\\nconstruct a GCR, AF (in fact, scattered) subalgebra $A$ of $B(\\ell_2)$, which\\nis the inductive limit of length $\\omega_1$ of its separable stable ideals\\n$I_\\alpha$ ($\\alpha<\\omega_1$) satisfying $I_{\\alpha+1}/I_\\alpha\\cong\\nK(\\ell_2)$ for each $\\alpha<\\omega_1$, while $A$ is not stable.\\nThe sequence $(I_\\alpha)_{\\alpha\\leq\\omega_1}$ is the GCR composition series\\nof $A$ which in this case coincides with the Cantor-Bendixson composition\\nseries as a scattered C*-algebra. $A$ has the property that all of its proper\\ntwo-sided ideals are listed as $I_\\alpha$s for some $\\alpha<\\omega_1$ and\\ntherefore the family of stable ideals of $A$ has no maximal element.\\nBy taking $A'=A\\otimes K(\\ell_2)$ we obtain a stable C*-algebra with\\nanalogous composition series $(J_\\alpha)_{\\alpha<\\omega_1}$ whose ideals\\n$J_\\alpha$s are isomorphic to $I_\\alpha$s for each $\\alpha<\\omega_1$. In\\nparticular, there are nonisomorphic scattered C*-algebras whose GCR composition\\nseries $(I_\\alpha)_{\\alpha\\leq\\omega_1}$ satisfy $I_{\\alpha+1}/I_\\alpha\\cong\\nK(\\ell_2)$ for all $\\alpha<\\omega_1$, for which the composition series differ\\nfirst at $\\alpha=\\omega_1$.\\n    1\n",
       "  New finite element methods are proposed for elliptic interface problems in\\none and two dimensions. The main motivation is not only to get an accurate\\nsolution but also an accurate first order derivative at the interface (from\\neach side). The key in 1D is to use the idea from \\cite{wheeler1974galerkin}.\\nFor 2D interface problems, the idea is to introduce a small tube near the\\ninterface and introduce the gradient as part of unknowns, which is similar to a\\nmixed finite element method, except only at the interface. Thus the\\ncomputational cost is just slightly higher than the standard finite element\\nmethod. We present rigorous one dimensional analysis, which show second order\\nconvergence order for both of the solution and the gradient in 1D. For two\\ndimensional problems, we present numerical results and observe second order\\nconvergence for the solution, and super-convergence for the gradient at the\\ninterface.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1\n",
       "  Energy storage systems (EES) are expected to be an indispensable resource for\\nmitigating the effects on networks of high penetrations of distributed\\ngeneration in the near future. This paper analyzes the benefits of EES in\\nunbalanced low voltage (LV) networks regarding three aspects, namely, power\\nlosses, the hosting capacity and network unbalance. For doing so, a mixed\\ninteger quadratic programmming model (MIQP) is developed to minimize annual\\nenergy losses and determine the sizing and placement of ESS, while satisfying\\nvoltage constraints. A real unbalanced LV UK grid is adopted to examine the\\neffects of ESS under two scenarios: the installation of one community ESS\\n(CESS) and multiple distributed ESSs (DESSs). The results illustrate that both\\nscenarios present high performance in accomplishing the above tasks, while\\nDESSs, with the same aggregated size, are slightly better. This margin is\\nexpected to be amplified as the aggregated size of DESSs increases.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ..\n",
       "  Many important complex networks, including critical infrastructure and\\nemerging industrial automation systems, are becoming increasingly intricate\\nwebs of interacting feedback control loops. A fundamental concern is to\\nquantify the control properties and performance limitations of the network as a\\nfunction of its dynamical structure and control architecture. We study\\nperformance bounds for networks in terms of optimal feedback control costs. We\\nprovide a set of complementary bounds as a function of the system dynamics and\\nactuator structure. For unstable network dynamics, we characterize a tradeoff\\nbetween feedback control performance and the number of control inputs, in\\nparticular showing that optimal cost can increase exponentially with the size\\nof the network. We also derive a bound on the performance of the worst-case\\nactuator subset for stable networks, providing insight into dynamics properties\\nthat affect the potential efficacy of actuator selection. We illustrate our\\nresults with numerical experiments that analyze performance in regular and\\nrandom networks.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
       "  We present a unified framework for Batch Online Learning (OL) for Click\\nPrediction in Search Advertisement. Machine Learning models once deployed, show\\nnon-trivial accuracy and calibration degradation over time due to model\\nstaleness. It is therefore necessary to regularly update models, and do so\\nautomatically. This paper presents two paradigms of Batch Online Learning, one\\nwhich incrementally updates the model parameters via an early stopping\\nmechanism, and another which does so through a proximal regularization. We\\nargue how both these schemes naturally trade-off between old and new data. We\\nthen theoretically and empirically show that these two seemingly different\\nschemes are closely related. Through extensive experiments, we demonstrate the\\nutility of of our OL framework; how the two OL schemes relate to each other and\\nhow they trade-off between the new and historical data. We then compare batch\\nOL to full model retrains, and show how online learning is more robust to data\\nissues. We also demonstrate the long term impact of Online Learning, the role\\nof the initial Models in OL, the impact of delays in the update, and finally\\nconclude with some implementation details and challenges in deploying a real\\nworld online learning system in production. While this paper mostly focuses on\\napplication of click prediction for search advertisement, we hope that the\\nlessons learned here can be carried over to other problem domains.\\n                                                                                 1\n",
       "  For many important network types (e.g., sensor networks in complex harsh\\nenvironments and social networks) physical coordinate systems (e.g.,\\nCartesian), and physical distances (e.g., Euclidean), are either difficult to\\ndiscern or inapplicable. Accordingly, coordinate systems and characterizations\\nbased on hop-distance measurements, such as Topology Preserving Maps (TPMs) and\\nVirtual-Coordinate (VC) systems are attractive alternatives to Cartesian\\ncoordinates for many network algorithms. Herein, we present an approach to\\nrecover geometric and topological properties of a network with a small set of\\ndistance measurements. In particular, our approach is a combination of shortest\\npath (often called geodesic) recovery concepts and low-rank matrix completion,\\ngeneralized to the case of hop-distances in graphs. Results for sensor networks\\nembedded in 2-D and 3-D spaces, as well as a social networks, indicates that\\nthe method can accurately capture the network connectivity with a small set of\\nmeasurements. TPM generation can now also be based on various context\\nappropriate measurements or VC systems, as long as they characterize different\\nnodes by distances to small sets of random nodes (instead of a set of global\\nanchors). The proposed method is a significant generalization that allows the\\ntopology to be extracted from a random set of graph shortest paths, making it\\napplicable in contexts such as social networks where VC generation may not be\\npossible.\\n                                                        1\n",
       "  Using a field-effect transistor (FET) configuration with solid Li-ion\\nconductor (SIC) as gate dielectric, we have successfully tuned carrier density\\nin FeSe$_{0.5}$Te$_{0.5}$ thin flakes, and the electronic phase diagram has\\nbeen mapped out. It is found that electron doping controlled by SIC-FET leads\\nto a suppression of the superconducting phase, and eventually gives rise to an\\ninsulating state in FeSe$_{0.5}$Te$_{0.5}$. During the gating process, the\\n(001) peak in XRD patterns stays at the same position and no new diffraction\\npeak emerges, indicating no evident Li$^+$ ions intercalation into the\\nFeSe$_{0.5}$Te$_{0.5}$. It indicates that a systematic change of electronic\\nproperties in FeSe$_{0.5}$Te$_{0.5}$ arises from the electrostatic doping\\ninduced by the accumulation of Li$^+$ ions at the interface between\\nFeSe$_{0.5}$Te$_{0.5}$ and solid ion conductor in the devices. It is striking\\nthat these findings are drastically different from the observation in FeSe thin\\nflakes using the same SIC-FET, in which $T_c$ is enhanced from 8 K to larger\\nthan 40 K, then the system goes into an insulating phase accompanied by\\nstructural transitions.\\n                                                                                                                                                                                                                                                                                                                                                                                        1\n",
       "  Superconducting and normal state properties of sputtered Niobium nanofilms\\nhave been systematically investigated, as a function of film thickness in a\\nd=9-90 nm range, on different substrates. The width of the\\nsuperconducting-to-normal transition for all films remained in few tens of mK,\\nthus remarkably narrow, confirming their high quality. We found that the\\nsuperconducting critical current density exhibits a pronounced maximum, three\\ntimes larger than its bulk value, for film thickness around 25 nm, marking the\\n3D-to-2D crossover. The extracted magnetic penetration depth shows a sizeable\\nenhancement for the thinnest films, aside the usual demagnetization effects.\\nAdditional amplification effects of the superconducting properties have been\\nobtained in the case of sapphire substrates or squeezing the lateral size of\\nthe nanofilms. For thickness close to 20 nm we also measured a doubled\\nperpendicular critical magnetic field compared to its saturation value for d>33\\nnm, indicating shortening of the correlation length and the formation of small\\nCooper pairs in the condensate. Our data analysis evidences an exciting\\ninterplay between quantum-size and proximity effects together with\\nstrong-coupling effects and importance of disorder in the thinnest films,\\nlocating the ones with optimally enhanced critical properties close to the\\nBCS-BEC crossover regime.\\n                                                                                                                                                           1\n",
       "Name: ABSTRACT, Length: 8989, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.ABSTRACT.value_counts())\n",
    "print(\"_\"*120)\n",
    "display(test.ABSTRACT.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20972"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8989"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.ABSTRACT.nunique())\n",
    "print(\"_\"*120)\n",
    "display(test.ABSTRACT.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
